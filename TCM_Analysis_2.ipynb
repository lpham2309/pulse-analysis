{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cc3a28-399b-4788-bca7-84f61358b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "NUM_SYNDROMES = 13\n",
    "NUM_SYMPTOMS = 81\n",
    "NUM_ITERATIONS = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e818632a-4f04-43d0-9cd8-aed38e55cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcm_data = pd.read_csv(\"FILE_NAME\", usecols=lambda x: x != \"ID\")\n",
    "tcm_x, tcm_y = tcm_data.shape\n",
    "tcm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7447cc35-26a3-43d9-9cda-4c37f28c757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tcm_data)\n",
    "shift_cols = [\"HTN\", \"DM\", \"CHD\", \"CVD\"]\n",
    "\n",
    "for i in range(len(shift_cols)):\n",
    "    col_name = df.pop(shift_cols[i])\n",
    "    df.insert(tcm_y-1, shift_cols[i], col_name)  \n",
    "\n",
    "df = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a416ba-0bd0-457f-b750-da16aa379aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLModel():\n",
    "    def __init__(self, instance):\n",
    "        self.name = str(instance.__name__)\n",
    "        if self.name == \"LogisticRegression\":\n",
    "            self.instance = instance(random_state=0, C=0.1)\n",
    "        elif self.name == \"SVM\":\n",
    "            param_grid = {\n",
    "                \"kernel\": \"poly\"\n",
    "            }\n",
    "            self.instance = GridSearch(estimator=instance, param_grid=param_grid, cv=5)\n",
    "        else:\n",
    "            self.instance = instance()\n",
    "        self.accuracy = 0.0\n",
    "        self.mean = 0.0\n",
    "        self.std = 0.0\n",
    "        self.sqrt_mean = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f18fc1c-c83d-4b96-b8c8-341fa87e4493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_balanced_data(input_data, syndrome_col):\n",
    "    zero_data = input_data[input_data[:,syndrome_col] == 0]\n",
    "    one_data = input_data[input_data[:,syndrome_col] == 1]\n",
    "\n",
    "    zero_r, zero_c = zero_data.shape\n",
    "    one_r, one_c = one_data.shape\n",
    "\n",
    "    if zero_r > one_r:\n",
    "        np.random.shuffle(zero_data)\n",
    "        balanced_data = np.concatenate((zero_data[0:one_r,:],one_data), axis=0)\n",
    "    else:\n",
    "        np.random.shuffle(one_data)\n",
    "        balanced_data = np.concatenate((zero_data,one_data[0:zero_r,:]), axis=0)\n",
    "\n",
    "    return balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4240afbf-cb8f-4732-8c58-17b089c383f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml_models = [MLModel(instance=DecisionTreeClassifier), MLModel(instance=SVC), MLModel(instance=LogisticRegression), MLModel(instance=RandomForestClassifier), MLModel(instance=KNeighborsClassifier), MLModel(instance=Perceptron)]\n",
    "ml_models = [MLModel(instance=SVC)]\n",
    "extended_models = [[m for m in ml_models] for _ in range(NUM_SYNDROMES)]\n",
    "avg_acc = []\n",
    "def run_each_syndrome_measurement_once():\n",
    "    for sdr_f in range(NUM_SYNDROMES):\n",
    "        # print(f\"R{sdr_f+1}\")\n",
    "        data = update_balanced_data(df, NUM_SYMPTOMS + sdr_f)\n",
    "        print(f'R{sdr_f+1} - Balanced data shape: {data.shape}')\n",
    "        \n",
    "        train_data = data[:,:NUM_SYMPTOMS]\n",
    "        test_data = data[:, NUM_SYMPTOMS+sdr_f]\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(train_data, test_data, test_size=0.3)\n",
    "\n",
    "        X1_test, X2_test = np.array_split(X_test, 2)\n",
    "        Y1_test, Y2_test = np.array_split(Y_test, 2)\n",
    "\n",
    "        kfold = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "  \n",
    "        for model in range(len(ml_models)):\n",
    "            clf = extended_models[sdr_f][model].instance\n",
    "            clf.fit(X_train, Y_train)\n",
    "            # Model score\n",
    "            model_score = clf.score(X_test, Y_test)\n",
    "\n",
    "            # Get confident score base on X_test\n",
    "            Y_pred = clf.predict(X_test)\n",
    "\n",
    "            score_sdt_p1 = clf.score(X1_test, Y1_test)\n",
    "            np.random.shuffle(Y2_test)\n",
    "            score_sdt_p2 = clf.score(X2_test, Y2_test)\n",
    "\n",
    "            \n",
    "            # pred_acc = accuracy_score(Y_test, Y_pred)\n",
    "            extended_models[sdr_f][model].accuracy += model_score\n",
    "\n",
    "            mean_sqrt_error = mean_squared_error(Y_test, Y_pred)\n",
    "            extended_models[sdr_f][model].sqrt_mean += mean_sqrt_error\n",
    "            \n",
    "            val_score = cross_val_score(clf, X_train, Y_train, cv=kfold)\n",
    "            extended_models[sdr_f][model].std += val_score.std()\n",
    "            extended_models[sdr_f][model].mean += val_score.mean()\n",
    "            \n",
    "            avg_acc.append(model_score * 100)\n",
    "            \n",
    "\n",
    "            print(f\"Name: {extended_models[sdr_f][model].name}   Accuracy: {model_score * 100:.3f}%   Squared Mean: {mean_sqrt_error:.3f}   Standard Deviation: {val_score.std():.3f}   Mean: {val_score.mean():.3f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636f9113-c92e-47a3-b697-f845d60d82f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_each_syndrome_measurement_once()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1874d91a-48df-4f7e-847b-22be12bbe126",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(NUM_ITERATIONS):\n",
    "    print(f\"Starting iteration: {m+1}\")\n",
    "    run_each_syndrome_measurement_once()\n",
    "\n",
    "for i in range(NUM_SYNDROMES):\n",
    "    for j in range(len(ml_models)):\n",
    "        extended_models[i][j].accuracy /= NUM_ITERATIONS\n",
    "        extended_models[i][j].sqrt_mean /= NUM_ITERATIONS\n",
    "        extended_models[i][j].std /= NUM_ITERATIONS\n",
    "        extended_models[i][j].mean /= NUM_ITERATIONS\n",
    "        print(f\"R{i+1}\\n\")\n",
    "        print(f\"Name: {extended_models[i][j].name}   Accuracy: {(extended_models[i][j].accuracy // NUM_SYNDROMES)*100:.3f}%  Mean Squared Error: {(extended_models[i][j].sqrt_mean // NUM_SYNDROMES):.3f}    Standard Dev: {extended_models[i][j].std // NUM_SYNDROMES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a99d26-25b9-457d-b0ff-81caebbd091a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
